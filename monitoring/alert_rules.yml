# Prometheus alert rules for IndoBERT Document Customer Service

groups:
  - name: indobert_api_alerts
    rules:
      # API availability
      - alert: APIDown
        expr: up{job="indobert-api"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "IndoBERT API is down"
          description: "The IndoBERT Document CS API has been down for more than 1 minute."

      # High error rate
      - alert: HighErrorRate
        expr: |
          (
            rate(http_requests_total{job="indobert-api",status=~"5.."}[5m]) /
            rate(http_requests_total{job="indobert-api"}[5m])
          ) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes."

      # High response time
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95, 
            rate(http_request_duration_seconds_bucket{job="indobert-api"}[5m])
          ) > 5
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "High response time"
          description: "95th percentile response time is {{ $value }}s for the last 5 minutes."

      # Low success rate
      - alert: LowSuccessRate
        expr: |
          (
            rate(http_requests_total{job="indobert-api",status=~"2.."}[5m]) /
            rate(http_requests_total{job="indobert-api"}[5m])
          ) < 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low success rate"
          description: "Success rate is {{ $value | humanizePercentage }} for the last 5 minutes."

  - name: system_alerts
    rules:
      # High CPU usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (
            (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / 
            node_memory_MemTotal_bytes
          ) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

      # Low disk space
      - alert: LowDiskSpace
        expr: |
          (
            (node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes{fstype!="tmpfs"}) / 
            node_filesystem_size_bytes{fstype!="tmpfs"}
          ) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space"
          description: "Disk usage is {{ $value }}% on {{ $labels.instance }} mount {{ $labels.mountpoint }}"

      # High disk I/O
      - alert: HighDiskIO
        expr: irate(node_disk_io_time_seconds_total[5m]) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High disk I/O"
          description: "Disk I/O time is {{ $value }}% on {{ $labels.instance }} device {{ $labels.device }}"

  - name: docker_alerts
    rules:
      # Container down
      - alert: ContainerDown
        expr: absent(container_last_seen{name=~"indobert.*"})
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Container is down"
          description: "Container {{ $labels.name }} is down"

      # High container CPU
      - alert: ContainerHighCPU
        expr: |
          (
            rate(container_cpu_usage_seconds_total{name=~"indobert.*"}[5m]) * 100
          ) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Container high CPU usage"
          description: "Container {{ $labels.name }} CPU usage is {{ $value }}%"

      # High container memory
      - alert: ContainerHighMemory
        expr: |
          (
            container_memory_usage_bytes{name=~"indobert.*"} / 
            container_spec_memory_limit_bytes{name=~"indobert.*"}
          ) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Container high memory usage"
          description: "Container {{ $labels.name }} memory usage is {{ $value }}%"

  - name: model_alerts
    rules:
      # High inference time
      - alert: HighInferenceTime
        expr: |
          histogram_quantile(0.95, 
            rate(model_inference_duration_seconds_bucket[5m])
          ) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High model inference time"
          description: "95th percentile inference time is {{ $value }}s"

      # Low cache hit rate
      - alert: LowCacheHitRate
        expr: |
          (
            rate(model_cache_hits_total[5m]) /
            (rate(model_cache_hits_total[5m]) + rate(model_cache_misses_total[5m]))
          ) < 0.7
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Low model cache hit rate"
          description: "Cache hit rate is {{ $value | humanizePercentage }}"

      # High GPU memory usage (if GPU is used)
      - alert: HighGPUMemory
        expr: |
          (
            nvidia_ml_py_memory_used_bytes / 
            nvidia_ml_py_memory_total_bytes
          ) * 100 > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High GPU memory usage"
          description: "GPU memory usage is {{ $value }}% on GPU {{ $labels.gpu }}"

  - name: application_alerts
    rules:
      # High number of errors in logs
      - alert: HighLogErrors
        expr: increase(log_messages_total{level="error"}[5m]) > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High number of errors in logs"
          description: "{{ $value }} errors logged in the last 5 minutes"

      # Queue backlog (if using message queues)
      - alert: QueueBacklog
        expr: queue_size > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Queue backlog detected"
          description: "Queue {{ $labels.queue }} has {{ $value }} pending messages"

      # Database connection issues (if using database)
      - alert: DatabaseConnectionIssues
        expr: database_connections_failed_total > 5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Database connection issues"
          description: "{{ $value }} database connection failures detected"

      # Webhook failures (if using webhooks)
      - alert: WebhookFailures
        expr: increase(webhook_requests_failed_total[5m]) > 3
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Webhook failures detected"
          description: "{{ $value }} webhook failures in the last 5 minutes"
